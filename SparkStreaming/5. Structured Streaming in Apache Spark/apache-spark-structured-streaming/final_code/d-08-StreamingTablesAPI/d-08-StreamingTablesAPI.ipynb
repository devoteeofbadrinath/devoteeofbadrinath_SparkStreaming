{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4009b58e",
   "metadata": {},
   "source": [
    "### TODO Recording:\n",
    "\n",
    "- Set up the input/ folder, should be empty\n",
    "- Delete the checkpoint folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483dc45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/13 08:44:23 WARN Utils: Your hostname, Jananis-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.68.52 instead (on interface en0)\n",
      "25/02/13 08:44:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/13 08:44:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StreamingTableDemo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1717b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, \\\n",
    "    StringType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Rank\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Manufacturer\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Segment\", StringType(), True),\n",
    "    StructField(\"Total_Cores\", IntegerType(), True),\n",
    "    StructField(\"Processor_Speed\", IntegerType(), True),\n",
    "    StructField(\"CoProcessor_Cores\", IntegerType(), True),\n",
    "    StructField(\"Rmax\", DoubleType(), True),\n",
    "    StructField(\"Rpeak\", DoubleType(), True),\n",
    "    StructField(\"Power\", DoubleType(), True),\n",
    "    StructField(\"Power_Efficiency\", DoubleType(), True),\n",
    "    StructField(\"Architecture\", StringType(), True),\n",
    "    StructField(\"Processor_Technology\", StringType(), True),\n",
    "    StructField(\"Operating_System\", StringType(), True),\n",
    "    StructField(\"OS_Family\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac38c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = spark.readStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"input/\")\n",
    "\n",
    "selected_df = streaming_df.select(\n",
    "    \"Name\", \"Manufacturer\", \"Country\", \"Year\", \"Segment\", \"Power\", \"Architecture\"\n",
    ").filter(col(\"Segment\") == \"Vendor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba597ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/13 08:44:27 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fa6c1ea07c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df.writeStream \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint_orig/\") \\\n",
    "    .toTable(\"supercomputers_streaming_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81db74",
   "metadata": {},
   "source": [
    "### TODO Recording:\n",
    "\n",
    "- Show the spark_warehouse/ folder created in the directory\n",
    "- Show the contents of this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5f9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+----+-------+------+------------+\n",
      "|                Name|   Manufacturer|      Country|Year|Segment| Power|Architecture|\n",
      "+--------------------+---------------+-------------+----+-------+------+------------+\n",
      "|              Selene|         Nvidia|United States|2020| Vendor|2646.0|     Cluster|\n",
      "|        Voyager-EUS2|Microsoft Azure|United States|2021| Vendor|  NULL|     Cluster|\n",
      "|         Pioneer-EUS|Microsoft Azure|United States|2020| Vendor|  NULL|     Cluster|\n",
      "|        Pioneer-SCUS|Microsoft Azure|United States|2021| Vendor|  NULL|     Cluster|\n",
      "|         Pioneer-WEU|Microsoft Azure|  Netherlands|2021| Vendor|  NULL|     Cluster|\n",
      "|NVIDIA Cambridge-...|         Nvidia|United States|2021| Vendor|  NULL|     Cluster|\n",
      "+--------------------+---------------+-------------+----+-------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"supercomputers_streaming_table\").show(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a56f1f",
   "metadata": {},
   "source": [
    "### TODO Recording:\n",
    "\n",
    "- Add a file to the input/ folder\n",
    "- Re-run the previous cell - should have contents in the streaming table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d2d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                                                                                            |comment|\n",
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|Name                        |string                                                                                                                                                               |NULL   |\n",
      "|Manufacturer                |string                                                                                                                                                               |NULL   |\n",
      "|Country                     |string                                                                                                                                                               |NULL   |\n",
      "|Year                        |int                                                                                                                                                                  |NULL   |\n",
      "|Segment                     |string                                                                                                                                                               |NULL   |\n",
      "|Power                       |double                                                                                                                                                               |NULL   |\n",
      "|Architecture                |string                                                                                                                                                               |NULL   |\n",
      "|                            |                                                                                                                                                                     |       |\n",
      "|# Detailed Table Information|                                                                                                                                                                     |       |\n",
      "|Catalog                     |spark_catalog                                                                                                                                                        |       |\n",
      "|Database                    |default                                                                                                                                                              |       |\n",
      "|Table                       |supercomputers_streaming_table                                                                                                                                       |       |\n",
      "|Created Time                |Thu Feb 13 08:44:27 IST 2025                                                                                                                                         |       |\n",
      "|Last Access                 |UNKNOWN                                                                                                                                                              |       |\n",
      "|Created By                  |Spark 3.5.4                                                                                                                                                          |       |\n",
      "|Type                        |MANAGED                                                                                                                                                              |       |\n",
      "|Provider                    |parquet                                                                                                                                                              |       |\n",
      "|Location                    |file:/Users/janani/Desktop/iMovieLibrary/Pluralsight/StructuredStreamingApacheSpark/final_code/d-08-StreamingTablesAPI/spark-warehouse/supercomputers_streaming_table|       |\n",
      "+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED supercomputers_streaming_table\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a970ec",
   "metadata": {},
   "source": [
    "Read from the streaming table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eea52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = spark.readStream \\\n",
    "    .table(\"supercomputers_streaming_table\")\\\n",
    "    .filter(col(\"Year\") >= 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e193b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/13 08:44:49 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fa6c206b730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------------------------------+---------------+-------------+----+-------+------+------------+\n",
      "|Name                           |Manufacturer   |Country      |Year|Segment|Power |Architecture|\n",
      "+-------------------------------+---------------+-------------+----+-------+------+------------+\n",
      "|Selene                         |Nvidia         |United States|2020|Vendor |2646.0|Cluster     |\n",
      "|Voyager-EUS2                   |Microsoft Azure|United States|2021|Vendor |NULL  |Cluster     |\n",
      "|Pioneer-EUS                    |Microsoft Azure|United States|2020|Vendor |NULL  |Cluster     |\n",
      "|Pioneer-SCUS                   |Microsoft Azure|United States|2021|Vendor |NULL  |Cluster     |\n",
      "|Pioneer-WEU                    |Microsoft Azure|Netherlands  |2021|Vendor |NULL  |Cluster     |\n",
      "|NVIDIA Cambridge-1 DGX SuperPOD|Nvidia         |United States|2021|Vendor |NULL  |Cluster     |\n",
      "+-------------------------------+---------------+-------------+----+-------+------+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------+------------+-------------+----+-------+-----+------------+\n",
      "|Name        |Manufacturer|Country      |Year|Segment|Power|Architecture|\n",
      "+------------+------------+-------------+----+-------+-----+------------+\n",
      "|DGX SuperPOD|Nvidia      |United States|2020|Vendor |NULL |Cluster     |\n",
      "+------------+------------+-------------+----+-------+-----+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "|Name|Manufacturer|Country|Year|Segment|Power|Architecture|\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "|Name|Manufacturer|Country|Year|Segment|Power|Architecture|\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "+----+------------+-------+----+-------+-----+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------+------------+-------+----+-------+-----+------------+\n",
      "|Name    |Manufacturer|Country|Year|Segment|Power|Architecture|\n",
      "+--------+------------+-------+----+-------+-----+------------+\n",
      "|Spartan3|Atos        |France |2021|Vendor |NULL |Cluster     |\n",
      "+--------+------------+-------+----+-------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df\\\n",
    "    .writeStream.option(\"checkpointLocation\", \"checkpoint_new/\")\\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1803a75e",
   "metadata": {},
   "source": [
    "### TODO Recording:\n",
    "\n",
    "- Add files 2,3,4,5 to the input/ folder and watch the console output here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeee1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
